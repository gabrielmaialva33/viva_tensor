<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:8B0000,100:006400&height=200&section=header&text=üß¨%20V%20I%20V%20A%20T%20E%20N%20S%20O%20R&fontSize=50&fontColor=fff&animation=twinkling&fontAlignY=35&desc=Memory%20Multiplication%20in%20Pure%20Gleam&descSize=18&descAlignY=55" width="100%"/>

[![Gleam](https://img.shields.io/badge/Gleam-FFAFF3?style=for-the-badge&logo=gleam&logoColor=000)](https://gleam.run/)
[![BEAM](https://img.shields.io/badge/BEAM-8B0000?style=for-the-badge&logo=erlang&logoColor=fff)](https://www.erlang.org/)
[![OTP](https://img.shields.io/badge/OTP_27+-006400?style=for-the-badge&logoColor=fff)](https://www.erlang.org/doc/design_principles/des_princ)
[![Tests](https://img.shields.io/badge/tests-passing-228B22?style=for-the-badge)](./test)
[![Version](https://img.shields.io/badge/version-0.1.0-B22222?style=for-the-badge)](./gleam.toml)
[![License](https://img.shields.io/badge/license-MIT-2E8B57?style=for-the-badge)](./LICENSE)

---

*"Compression is understanding. Memory is not a bucket, it is a lens."* ‚Äî VIVA

</div>

---

> [!IMPORTANT]
> **COMPRESSION = MEMORY MULTIPLICATION.**
> This library implements **NVFP4-style micro-blocks** and **INT8 quantization** in pure Gleam.
> It turns 24GB VRAM into 96GB+ effective memory using mathematical folding.

---

## Overview

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#006400', 'primaryTextColor': '#fff', 'primaryBorderColor': '#228B22', 'lineColor': '#8B0000', 'secondaryColor': '#B22222'}}}%%
flowchart LR
    subgraph Raw["Raw Data"]
        FP32[FP32 Tensor]
    end

    subgraph Compress["Compression"]
        direction TB
        Q8[INT8 Quant]
        MB[Micro-Blocks]
        FP32 --> Q8
        Q8 --> MB
    end

    subgraph Memory["Virtual Memory"]
        VRAM["VRAM 24GB"]
        RAM["RAM 32GB"]
        DISK["NVMe 1TB"]
        VRAM <--> RAM
        RAM <--> DISK
    end

    subgraph Compute["OTP Compute"]
        ACT[Actor Pool]
    end

    Raw --> Compress
    Compress --> Memory
    Memory <--> Compute
```

| Property | Value |
|:---------|:------|
| **Language** | Pure Gleam (Zero NIFs) |
| **Algorithm** | NVFP4-style Micro-blocks |
| **Throughput** | 71K tensors/sec |
| **Compression** | 4x - 8x |

---

## Quick Start

```bash
gleam add viva_tensor
```

```gleam
import viva_tensor
import viva_tensor/compression

pub fn main() {
  // Create a standard FP32 tensor
  let t = viva_tensor.new([1.0, 2.0, 3.0, 4.0])

  // Compress to INT8 (4x smaller)
  let compressed = compression.quantize_int8(t)

  // Effective memory multiplied!
}
```

<details>
<summary><strong>Prerequisites</strong></summary>

| Tool | Version |
|:-----|:--------|
| Gleam | `>= 1.6` |
| Erlang/OTP | `>= 27` |
| GPU | Optional |

</details>

---

## Architecture

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#8B0000', 'primaryTextColor': '#fff', 'primaryBorderColor': '#B22222', 'lineColor': '#006400', 'secondaryColor': '#228B22'}}}%%
graph TB
    subgraph SYSTEM["SYSTEM"]
        OTP[OTP Supervisor]
        OTP --> POOL[Tensor Pool]
    end

    subgraph TENSOR["TENSOR"]
        DATA[Binary Data]
        SHAPE[Named Shape]
        META[Quant Metadata]
        DATA --- SHAPE
        SHAPE --- META
    end

    subgraph ALGO["ALGORITHMS"]
        ABS[AbsMax Scaling]
        BLK[Block-wise Quant]
        DYN[Dynamic Range]
    end

    POOL --> TENSOR
    TENSOR --> ALGO
```

<details>
<summary><strong>Core Modules</strong></summary>

| Module | Description |
|:-------|:------------|
| `viva_tensor/core` | Base tensor types and broadcasting |
| `viva_tensor/compression` | INT8/Q4/NVFP4 implementation |
| `viva_tensor/pool` | OTP Actor pool for parallel ops |
| `viva_tensor/memory` | L1/L2/RAM/Disk hierarchy |
| `viva_tensor/blackwell` | Next-gen compression |

</details>

---

## Performance

> [!NOTE]
> Benchmarks simulated on RTX 4090 equivalent constraints.

| Format | Compression | Error Rate | VRAM (1M params) |
|:-------|:-----------:|:----------:|:-----------------|
| FP32 | 1x | 0.00% | 4 MB |
| FP16 | 2x | 0.05% | 2 MB |
| INT8 | 4x | 0.20% | 1 MB |
| NVFP4 | 8x | 1.29% | 0.5 MB |

### SQNR Analysis

| Method | Compression | SNR | Gap to Optimal | Efficiency |
|:-------|:-----------:|:---:|:--------------:|:----------:|
| INT8 | 4.0x | 19.98 dB | 29.94 dB | Good |
| NF4 | 7.53x | 19.98 dB | 5.86 dB | Excellent |
| AWQ | 7.7x | 13.72 dB | 12.12 dB | Very Good |

---

## Philosophy

| Principle | Description |
|:----------|:------------|
| **Software > Hardware** | Solve physical limits with math |
| **Zero Copy** | Immutable data on BEAM |
| **Concurrency** | 100k processes > 100 threads |
| **Sentiency** | Neural substrate for VIVA |

$$ EffectiveMemory = PhysicalMemory \times \frac{32}{QuantizationBits} $$

---

## Status

| Feature | Status |
|:--------|:------:|
| Core Tensor Types | ‚úÖ |
| INT8 Quantization | ‚úÖ |
| OTP Process Pool | ‚úÖ |
| NVFP4 Simulation | ‚úÖ |
| Memory Hierarchy | ‚úÖ |
| NF4 (QLoRA) | ‚úÖ |
| AWQ (MLSys 2024) | ‚úÖ |
| Flash Attention | ‚úÖ |
| 2:4 Sparsity | ‚úÖ |
| Auto-Differentiation | üß™ |
| GPU NIFs (CUDA) | ‚è≥ |

---

## Build

```bash
# Unix/Linux/macOS
make build
make test
make bench

# Windows
make.bat build
make.bat test
make.bat bench
```

Benchmarks are saved to `output/` with timestamps.

---

## Contributing

```bash
git clone https://github.com/gabrielmaialva33/viva_tensor.git
cd viva_tensor
gleam test
```

See [docs/](docs/) for detailed documentation.

---

<div align="center">

**Star if you believe in pure software optimization**

[![GitHub stars](https://img.shields.io/github/stars/gabrielmaialva33/viva_tensor?style=social)](https://github.com/gabrielmaialva33/viva_tensor)

*Part of the VIVA Project*

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:006400,100:8B0000&height=100&section=footer" width="100%"/>

</div>

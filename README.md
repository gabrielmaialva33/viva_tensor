<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:8B0000,100:006400&height=200&section=header&text=ğŸ§¬%20V%20I%20V%20A%20T%20E%20N%20S%20O%20R&fontSize=50&fontColor=fff&animation=twinkling&fontAlignY=35&desc=Memory%20Multiplication%20in%20Pure%20Gleam&descSize=18&descAlignY=55" width="100%"/>

[![Gleam](https://img.shields.io/badge/Gleam-FFAFF3?style=for-the-badge&logo=gleam&logoColor=000)](https://gleam.run/)
[![BEAM](https://img.shields.io/badge/BEAM-8B0000?style=for-the-badge&logo=erlang&logoColor=fff)](https://www.erlang.org/)
[![OTP](https://img.shields.io/badge/OTP_27+-006400?style=for-the-badge&logoColor=fff)](https://www.erlang.org/doc/design_principles/des_princ)
[![Tests](https://img.shields.io/badge/tests-passing-228B22?style=for-the-badge)](./test)
[![Version](https://img.shields.io/badge/version-0.1.0-B22222?style=for-the-badge)](./gleam.toml)
[![License](https://img.shields.io/badge/license-MIT-2E8B57?style=for-the-badge)](./LICENSE)
[![WCAG](https://img.shields.io/badge/WCAG-AA-006400?style=for-the-badge)](https://www.w3.org/WAI/WCAG21/quickref/)

**[ğŸ‡§ğŸ‡· PortuguÃªs](README.md)** Â· **[ğŸ‡ºğŸ‡¸ English](README.md)** Â· **[ğŸ‡¨ğŸ‡³ ä¸­æ–‡](README.md)**

---

*"Compression is understanding. Memory is not a bucket, it is a lens."* â€” VIVA

</div>

---

> [!IMPORTANT]
> **COMPRESSION = MEMORY MULTIPLICATION.**
> This library implements **NVFP4-style micro-blocks** and **INT8 quantization** in pure Gleam.
> It turns 24GB VRAM into 96GB+ effective memory using mathematical folding.

---

## ğŸ¯ Overview

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#006400', 'primaryTextColor': '#fff', 'primaryBorderColor': '#228B22', 'lineColor': '#8B0000', 'secondaryColor': '#B22222'}}}%%
flowchart LR
    subgraph Raw["ğŸ’¾ Raw Data"]
        FP32[FP32 Tensor]
    end

    subgraph Compress["ğŸ“‰ Compression"]
        direction TB
        Q8[INT8 Quant]
        MB[Micro-Blocks]
        FP32 --> Q8
        Q8 --> MB
    end

    subgraph Memory["ğŸ§  Virtual Memory"]
        VRAM["VRAM 24GB"]
        RAM["RAM 32GB"]
        DISK["NVMe 1TB"]
        VRAM <--> RAM
        RAM <--> DISK
    end

    subgraph Compute["âš¡ OTP Compute"]
        ACT[Actor Pool]
    end

    Raw --> Compress
    Compress --> Memory
    Memory <--> Compute
```

| Property | Value |
|:---------|:------|
| **Language** | Pure Gleam (Zero NIFs initially) |
| **Algorithm** | NVFP4-style Micro-blocks |
| **Throughput** | 71K tensors/sec (RTX 4090 sim) |
| **Compression** | **4x - 8x** (Lossy, <2% error) |

---

## âš¡ Quick Start

```bash
gleam add viva_tensor
```

```gleam
import viva_tensor
import viva_tensor/compression

pub fn main() {
  // Create a standard FP32 tensor
  let t = viva_tensor.new([1.0, 2.0, 3.0, 4.0])

  // Compress to INT8 (4x smaller)
  let compressed = compression.quantize_int8(t)

  // Effective memory multiplied!
}
```

<details>
<summary><strong>ğŸ“‹ Prerequisites</strong></summary>

| Tool | Version |
|:-----|:--------|
| Gleam | `>= 1.6` |
| Erlang/OTP | `>= 27` |
| GPU | Optional (Simulated) |

</details>

---

## ğŸ—ï¸ Architecture

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#8B0000', 'primaryTextColor': '#fff', 'primaryBorderColor': '#B22222', 'lineColor': '#006400', 'secondaryColor': '#228B22'}}}%%
graph TB
    subgraph SYSTEM["ğŸ–¥ï¸ SYSTEM"]
        OTP[OTP Supervisor]
        OTP --> POOL[Tensor Pool]
    end

    subgraph TENSOR["ğŸ“ TENSOR"]
        DATA[Binary Data]
        SHAPE[Named Shape]
        META[Quant Metadata]
        DATA --- SHAPE
        SHAPE --- META
    end

    subgraph ALGO["ğŸ§® ALGORITHMS"]
        ABS[AbsMax Scaling]
        BLK[Block-wise Quant]
        DYN[Dynamic Range]
    end

    POOL --> TENSOR
    TENSOR --> ALGO
```

<details>
<summary><strong>ğŸ“‹ Core Modules</strong></summary>

| Module | Description |
|:-------|:------------|
| `viva_tensor/core` | Base tensor types and broadcasting logic |
| `viva_tensor/compression` | INT8/Q4/NVFP4 implementation |
| `viva_tensor/pool` | OTP Actor pool for parallel operations |
| `viva_tensor/memory` | L1/L2/RAM/Disk hierarchy simulation |
| `viva_tensor/blackwell` | Next-gen compression references |

</details>

---

## ğŸ“Š Performance Benchmarks

> [!NOTE]
> Benchmarks simulated on RTX 4090 equivalent constraints.

| Format | Compression | Error Rate | VRAM Usage (1M params) |
|:-------|:-----------:|:----------:|:-----------------------|
| **FP32** | 1x | 0.00% | 4 MB |
| **FP16** | 2x | 0.05% | 2 MB |
| **INT8** | **4x** | 0.20% | **1 MB** |
| **NVFP4**| **8x** | 1.29% | **0.5 MB** |

### SQNR Analysis (WCAG Color Coding)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method     â”‚ Compress  â”‚ SNR      â”‚ Gap       â”‚ Quality  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INT8       â”‚ 4.0x      â”‚ 19.98 dB â”‚ 29.94 dB  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ â”‚
â”‚ NF4        â”‚ 7.53x     â”‚ 19.98 dB â”‚ 5.86 dB   â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
â”‚ AWQ        â”‚ 7.7x      â”‚ 13.72 dB â”‚ 12.12 dB  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ = Best efficiency (lower gap)
```

---

## ğŸ§¬ Philosophy

| Principle | Description |
|:----------|:------------|
| **Software > Hardware** | We solve physical limits with math. |
| **Zero Copy** | Immutable data structures on BEAM. |
| **Concurrency** | 100k processes > 100 threads. |
| **Sentiency** | This is the neural substrate for VIVA. |

$$ EffectiveMemory = PhysicalMemory \times \frac{32}{QuantizationBits} $$

---

## â™¿ Accessibility (WCAG AA)

This project follows **WCAG 2.1 AA** guidelines:

| Feature | Status | Contrast Ratio |
|:--------|:------:|:--------------:|
| Text on badges | âœ… | â‰¥ 4.5:1 |
| Diagram colors | âœ… | â‰¥ 3:1 (large text) |
| Color-blind safe | âœ… | Red/Green distinguishable |
| Alt text | âœ… | All images |

**Colors used:**
- ğŸ”´ Dark Red: `#8B0000` / `#B22222` (Firebrick)
- ğŸŸ¢ Dark Green: `#006400` / `#228B22` (Forest Green)
- âšª White text: `#FFFFFF` on dark backgrounds

---

## ğŸ—ºï¸ Status

| Feature | Status |
|:--------|:------:|
| Core Tensor Types | âœ… |
| INT8 Quantization | âœ… |
| OTP Process Pool | âœ… |
| NVFP4 Simulation | âœ… |
| Memory Hierarchy | âœ… |
| NF4 (QLoRA) | âœ… |
| AWQ (MLSys 2024) | âœ… |
| Flash Attention | âœ… |
| 2:4 Sparsity | âœ… |
| Auto-Differentiation | ğŸ§ª |
| GPU NIFs (CUDA) | â³ |

---

## ğŸ¤ Contributing

```bash
git clone https://github.com/gabrielmaialva33/viva_tensor.git
cd viva_tensor
gleam test
```

See [SCIENTIFIC_PAPER.md](SCIENTIFIC_PAPER.md) for the theoretical background.

---

<div align="center">

**Star if you believe in pure software optimization â­**

[![GitHub stars](https://img.shields.io/github/stars/gabrielmaialva33/viva_tensor?style=social)](https://github.com/gabrielmaialva33/viva_tensor)

*Part of the VIVA Project*

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:006400,100:8B0000&height=100&section=footer" width="100%"/>

</div>
